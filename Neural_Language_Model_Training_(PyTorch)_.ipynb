{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhananjaneyulu/Assignment-2-Neural-Language-Model-Training-PyTorch-/blob/main/Neural_Language_Model_Training_(PyTorch)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9qzsI5wlhQYH"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q tqdm pandas matplotlib\n",
        "\n",
        "import os, time, math, json, random, re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ffkeDAhbyP",
        "outputId": "b81bf9be-fe55-4023-b53d-d8debd6c7d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device -> cpu\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# 2) Reproducibility & device\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Device ->', DEVICE)\n",
        "\n",
        "# %%\n",
        "# 3) Paths and helper functions\n",
        "DATA_FILE = '/content/Pride_and_Prejudice-Jane_Austen.txt'  # upload this file to Colab\n",
        "RESULTS_DIR = 'results'\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TgKrpvNzhb1T"
      },
      "outputs": [],
      "source": [
        "def clean_text(in_path, out_path):\n",
        "    txt = open(in_path, encoding='utf-8').read()\n",
        "    s = txt.find('*** START OF')\n",
        "    e = txt.find('*** END OF')\n",
        "    if s!=-1 and e!=-1:\n",
        "        txt = txt[s:e]\n",
        "    txt = txt.replace('\\r','\\n')\n",
        "    txt = re.sub('\\n{2,}','\\n', txt)\n",
        "    txt = re.sub(' +',' ', txt)\n",
        "    txt = txt.strip()\n",
        "    open(out_path,'w',encoding='utf-8').write(txt)\n",
        "    return txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLoCuMv8hb3-",
        "outputId": "d3ab5bb0-47e6-4d55-b6f2-ec293aa3d764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning text...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "CLEAN_FILE = 'data/pride_clean.txt'\n",
        "if not os.path.exists(CLEAN_FILE):\n",
        "    print('Cleaning text...')\n",
        "    clean_text(DATA_FILE, CLEAN_FILE)\n",
        "else:\n",
        "    print('Clean text exists.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr4bWKAEhb6d",
        "outputId": "9044792b-1cce-4d91-a525-c56325935c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 151819\n",
            "Vocab size: 4417\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# 4) Tokenization & vocab\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
        "\n",
        "text = open(CLEAN_FILE, encoding='utf-8').read()\n",
        "tokens = tokenize(text)\n",
        "print('Total tokens:', len(tokens))\n",
        "\n",
        "MIN_FREQ = 2\n",
        "counter = Counter(tokens)\n",
        "vocab_list = [tok for tok,cnt in counter.items() if cnt>=MIN_FREQ]\n",
        "special = ['<pad>','<unk>','<bos>','<eos>']\n",
        "itos = special + sorted(vocab_list)\n",
        "stoi = {w:i for i,w in enumerate(itos)}\n",
        "VOCAB_SIZE = len(itos)\n",
        "print('Vocab size:', VOCAB_SIZE)\n",
        "\n",
        "# encode\n",
        "ids = [stoi.get(t, stoi['<unk>']) for t in tokens]\n",
        "\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp_FzVWHh1BR",
        "outputId": "c6ffa777-c3f8-4049-a352-9e27c429e704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121455 15182 15182\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# 5) Train/Val/Test split (contiguous)\n",
        "N = len(ids)\n",
        "train_ids = ids[:int(0.8*N)]\n",
        "val_ids = ids[int(0.8*N):int(0.9*N)]\n",
        "test_ids = ids[int(0.9*N):]\n",
        "print(len(train_ids), len(val_ids), len(test_ids))\n",
        "\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZaZTJMdMh1D3"
      },
      "outputs": [],
      "source": [
        "class LMSeqDataset(Dataset):\n",
        "    def __init__(self, ids, seq_len, stride=1):\n",
        "        self.ids = ids\n",
        "        self.seq_len = seq_len\n",
        "        self.stride = stride\n",
        "        self.starts = list(range(0, max(0, len(ids)-seq_len), stride))\n",
        "    def __len__(self):\n",
        "        return len(self.starts)\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.starts[idx]\n",
        "        x = torch.tensor(self.ids[s:s+self.seq_len], dtype=torch.long)\n",
        "        y = torch.tensor(self.ids[s+1:s+self.seq_len+1], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FuT8A-abh_4x"
      },
      "outputs": [],
      "source": [
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "    def forward(self, x, hidden=None):\n",
        "        emb = self.embed(x)\n",
        "        out, hidden = self.lstm(emb, hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "990ae0b6",
        "outputId": "e05d60d0-3740-4400-f89d-342c06e190c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences in train_dataset: 24285\n",
            "\n",
            "Sample input sequence (x_sample) shape: torch.Size([30])\n",
            "Sample target sequence (y_sample) shape: torch.Size([30])\n",
            "Sample input sequence (first 5 tokens): tensor([ 347,  297,  155, 1619,   13])\n",
            "Sample target sequence (first 5 tokens): tensor([ 297,  155, 1619,   13,  295])\n"
          ]
        }
      ],
      "source": [
        "underfit_cfg = {\n",
        "    'seq_len': 30, 'batch_size': 64, 'stride':5,\n",
        "    'emb_dim': 50, 'hidden': 32, 'layers':1, 'dropout':0.5,\n",
        "    'lr':1e-3, 'epochs':8, 'clip':1.0\n",
        "}\n",
        "\n",
        "train_seq_len = underfit_cfg['seq_len']\n",
        "train_stride = underfit_cfg['stride']\n",
        "\n",
        "train_dataset = LMSeqDataset(train_ids, train_seq_len, stride=train_stride)\n",
        "\n",
        "print(f\"Number of sequences in train_dataset: {len(train_dataset)}\")\n",
        "\n",
        "# You can also access individual items (e.g., the first one)\n",
        "x_sample, y_sample = train_dataset[0]\n",
        "print(f\"\\nSample input sequence (x_sample) shape: {x_sample.shape}\")\n",
        "print(f\"Sample target sequence (y_sample) shape: {y_sample.shape}\")\n",
        "print(f\"Sample input sequence (first 5 tokens): {x_sample[:5]}\")\n",
        "print(f\"Sample target sequence (first 5 tokens): {y_sample[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b4ea6edf"
      },
      "outputs": [],
      "source": [
        "underfit_cfg = {\n",
        "    'seq_len': 30, 'batch_size': 64, 'stride':5,\n",
        "    'emb_dim': 50, 'hidden': 32, 'layers':1, 'dropout':0.5,\n",
        "    'lr':1e-3, 'epochs':8, 'clip':1.0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NzpvC27Dh_7W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%\n",
        "# 8) Training & evaluation functions\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_toks = 0\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='mean')\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(device); y=y.to(device)\n",
        "            logits,_ = model(x)\n",
        "            loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "            total_loss += loss.item() * x.size(0) * x.size(1)\n",
        "            total_toks += x.size(0) * x.size(1)\n",
        "    return total_loss / total_toks\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, opt, device, clip=1.0):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0, reduction='mean')\n",
        "    total_loss = 0.0\n",
        "    total_toks = 0\n",
        "    t0 = time.time()\n",
        "    for x,y in loader:\n",
        "        x=x.to(device); y=y.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits,_ = model(x)\n",
        "        loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * x.size(0) * x.size(1)\n",
        "        total_toks += x.size(0) * x.size(1)\n",
        "    t1 = time.time()\n",
        "    return total_loss/total_toks, (t1-t0)\n",
        "\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i-6nEPZth_9j"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%\n",
        "# 9) Experiment runner (runs until epochs or early stop)\n",
        "def run_experiment(name, config, early_stopping=None):\n",
        "    print('\\n=== Running:', name, '===')\n",
        "    seq_len = config['seq_len']\n",
        "    batch = config['batch_size']\n",
        "    stride = config.get('stride',1)\n",
        "    train_ds = LMSeqDataset(train_ids, seq_len, stride=stride)\n",
        "    val_ds = LMSeqDataset(val_ids, seq_len, stride=seq_len)  # val with non-overlapping windows\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch, shuffle=False, drop_last=False)\n",
        "\n",
        "    model = LSTMLM(VOCAB_SIZE, config['emb_dim'], config['hidden'], config['layers'], config['dropout']).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config.get('wd',0.0))\n",
        "\n",
        "    best_val = float('inf'); best_epoch = -1\n",
        "    history = {'train_loss':[], 'val_loss':[], 'epoch_time':[]}\n",
        "    for epoch in range(1, config['epochs']+1):\n",
        "        train_loss, epoch_time = train_one_epoch(model, train_loader, optimizer, DEVICE, clip=config.get('clip',1.0))\n",
        "        val_loss = evaluate(model, val_loader, DEVICE)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['epoch_time'].append(epoch_time)\n",
        "        print(f\"{name} Epoch {epoch}/{config['epochs']}  train={train_loss:.4f}  val={val_loss:.4f}  time={epoch_time:.1f}s\")\n",
        "        # save best\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            best_epoch = epoch\n",
        "            torch.save({'model':model.state_dict(), 'config':config}, os.path.join(RESULTS_DIR, f'{name}_best.pt'))\n",
        "        # early stopping\n",
        "        if early_stopping is not None and epoch - best_epoch >= early_stopping:\n",
        "            print('Early stopping triggered at epoch', epoch)\n",
        "            break\n",
        "    # evaluate test\n",
        "    test_loader = DataLoader(LMSeqDataset(test_ids, seq_len, stride=seq_len), batch_size=batch, shuffle=False)\n",
        "    test_loss = evaluate(model, test_loader, DEVICE)\n",
        "    best_state = torch.load(os.path.join(RESULTS_DIR, f'{name}_best.pt'), map_location=DEVICE)\n",
        "    result = {\n",
        "        'name': name,\n",
        "        'config': config,\n",
        "        'epochs_ran': len(history['train_loss']),\n",
        "        'train_loss_final': history['train_loss'][-1],\n",
        "        'val_loss_final': history['val_loss'][-1],\n",
        "        'val_ppl': math.exp(history['val_loss'][-1]) if history['val_loss'][-1] < 100 else float('inf'),\n",
        "        'test_loss': test_loss,\n",
        "        'test_ppl': math.exp(test_loss) if test_loss < 100 else float('inf'),\n",
        "        'best_val_loss': best_val,\n",
        "        'best_epoch': best_epoch,\n",
        "        'history': history\n",
        "    }\n",
        "    # save history\n",
        "    with open(os.path.join(RESULTS_DIR, f'{name}_history.json'),'w') as f:\n",
        "        json.dump(result, f)\n",
        "    return result\n",
        "\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a0C79JxRh__x"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 10) Experiment configurations\n",
        "underfit_cfg = {\n",
        "    'seq_len': 30, 'batch_size': 64, 'stride':5,\n",
        "    'emb_dim': 50, 'hidden': 32, 'layers':1, 'dropout':0.5,\n",
        "    'lr':1e-3, 'epochs':8, 'clip':1.0\n",
        "}\n",
        "\n",
        "overfit_cfg = {\n",
        "    'seq_len': 50, 'batch_size':64, 'stride':1,\n",
        "    'emb_dim': 400, 'hidden': 1024, 'layers':3, 'dropout':0.0,\n",
        "    'lr':5e-4, 'epochs':60, 'clip':1.0, 'wd':0.0\n",
        "}\n",
        "\n",
        "bestfit_cfg = {\n",
        "    'seq_len':50, 'batch_size':64, 'stride':1,\n",
        "    'emb_dim':200, 'hidden':256, 'layers':2, 'dropout':0.2,\n",
        "    'lr':1e-3, 'epochs':40, 'clip':1.0, 'wd':1e-5\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72b0c413",
        "outputId": "61f56859-02e1-4b71-d231-66e3e39496c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMLM(\n",
            "  (embed): Embedding(4417, 50, padding_idx=0)\n",
            "  (lstm): LSTM(50, 32, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=32, out_features=4417, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = LSTMLM(VOCAB_SIZE, underfit_cfg['emb_dim'], underfit_cfg['hidden'], underfit_cfg['layers'], underfit_cfg['dropout']).to(DEVICE)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE5hKZpaiABx",
        "outputId": "9fc2f7ee-abb8-4451-e943-56f3316c4d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Running: underfit ===\n",
            "underfit Epoch 1/8  train=6.2727  val=5.7538  time=67.3s\n",
            "underfit Epoch 2/8  train=5.5598  val=5.3675  time=66.2s\n",
            "underfit Epoch 3/8  train=5.2160  val=5.1171  time=67.4s\n",
            "underfit Epoch 4/8  train=4.9883  val=4.9648  time=67.0s\n",
            "underfit Epoch 5/8  train=4.8313  val=4.8617  time=67.8s\n",
            "underfit Epoch 6/8  train=4.7091  val=4.7846  time=67.1s\n",
            "underfit Epoch 7/8  train=4.6082  val=4.7288  time=67.2s\n",
            "underfit Epoch 8/8  train=4.5244  val=4.6841  time=67.8s\n",
            "\n",
            "=== Running: overfit ===\n"
          ]
        }
      ],
      "source": [
        "# 11) Run the 3 experiments sequentially\n",
        "results = []\n",
        "# 1) Underfit\n",
        "res_u = run_experiment('underfit', underfit_cfg, early_stopping=5)\n",
        "results.append(res_u)\n",
        "# 2) Overfit\n",
        "res_o = run_experiment('overfit', overfit_cfg, early_stopping=None)\n",
        "results.append(res_o)\n",
        "# 3) Best-fit (with early stopping patience=6)\n",
        "res_b = run_experiment('bestfit', bestfit_cfg, early_stopping=6)\n",
        "results.append(res_b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbC_HPW3iAD5"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# 12) Summarize results and plot curves\n",
        "summary_rows = []\n",
        "for r in results:\n",
        "    h = r['history']\n",
        "    epochs = len(h['train_loss'])\n",
        "    x = list(range(1, epochs+1))\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(x, h['train_loss'], label='train')\n",
        "    plt.plot(x, h['val_loss'], label='val')\n",
        "    plt.title(r['name'] + ' Loss curves')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f\"{r['name']}_loss.png\"))\n",
        "    plt.show()\n",
        "    summary_rows.append({\n",
        "        'name': r['name'],\n",
        "        'epochs_ran': r['epochs_ran'],\n",
        "        'best_epoch': r['best_epoch'],\n",
        "        'best_val_loss': r['best_val_loss'],\n",
        "        'val_ppl': r['val_ppl'],\n",
        "        'test_ppl': r['test_ppl']\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "print('\\nSummary:')\n",
        "display(summary_df)\n",
        "\n",
        "# %%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13) Save summary table\n",
        "summary_df.to_csv(os.path.join(RESULTS_DIR,'summary.csv'), index=False)\n",
        "print('All artifacts saved to', RESULTS_DIR)\n"
      ],
      "metadata": {
        "id": "66F7ROs5J0Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrRBq4iJh1GM"
      },
      "outputs": [],
      "source": [
        "# 14) Quick sampling function using best model from bestfit\n",
        "\n",
        "def sample_from_checkpoint(ckpt_path, seed_text='It is a truth', length=100, temp=1.0, top_k=50):\n",
        "    ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
        "    cfg = ckpt['config']\n",
        "    model = LSTMLM(VOCAB_SIZE, cfg['emb_dim'], cfg['hidden'], cfg['layers'], cfg['dropout']).to(DEVICE)\n",
        "    model.load_state_dict(ckpt['model'])\n",
        "    model.eval()\n",
        "    toks = tokenize(seed_text)\n",
        "    idxs = [stoi.get(t, stoi['<unk>']) for t in toks]\n",
        "    input_ids = torch.tensor([idxs], dtype=torch.long).to(DEVICE)\n",
        "    hidden=None\n",
        "    out = toks.copy()\n",
        "    for _ in range(length):\n",
        "        logits, hidden = model(input_ids[:, -cfg['seq_len']:], hidden)\n",
        "        logits = logits[:, -1, :]/max(1e-8, temp)\n",
        "        if top_k is not None:\n",
        "            v, ix = torch.topk(logits, top_k)\n",
        "            probs = torch.zeros_like(logits).scatter(1, ix, F.softmax(v, dim=-1))\n",
        "        else:\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "        nxt = torch.multinomial(probs, num_samples=1).item()\n",
        "        out.append(itos[nxt])\n",
        "        input_ids = torch.cat([input_ids, torch.tensor([[nxt]], device=DEVICE)], dim=1)\n",
        "    return ' '.join(out)\n",
        "\n",
        "# Try sampling\n",
        "bestfit_ckpt = os.path.join(RESULTS_DIR, 'bestfit_best.pt')\n",
        "if os.path.exists(bestfit_ckpt):\n",
        "    print('\\nSample from best-fit model:')\n",
        "    print(sample_from_checkpoint(bestfit_ckpt, seed_text='It is a truth universally acknowledged', length=60, temp=1.0, top_k=40))\n",
        "else:\n",
        "    print('Best-fit checkpoint not found yet.')\n",
        "\n",
        "# Notebook end\n",
        "print('\\nFinished. You can download the results folder for submission.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWRjCzcbBrU85me3Md9/Db",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}